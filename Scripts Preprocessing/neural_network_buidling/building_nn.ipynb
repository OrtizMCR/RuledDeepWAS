{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building neural network\n",
    "The main steps to create a neural network is to create the data loaders that will wrap around my dataset, and create the `class` that will represent the neural network.\n",
    "The neural network has to include two main functions, `__init__` and `forward`.\n",
    "For the DataLoader obejct there have to be 3 other functions, `init`, `len` and `getitem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import math\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases_path = \"/mnt/sda1/Databases/\"\n",
    "# GWAS Catalog path\n",
    "gwas_catalog_path = os.path.join(databases_path, \"GWAS_Catalog_DATA/gwas_catalog_v1.0.2-associations_e110_r2023-09-25.tsv\")\n",
    "# Ensembl Variation path\n",
    "ensembl_path = os.path.join(databases_path, \"Ensembl/Variation/110/\")\n",
    "# Chromosomes' data path\n",
    "chromosomes_path = os.path.join(ensembl_path, \"chromosomes_data/\")\n",
    "# Reference genome path\n",
    "ref_genome_path = os.path.join(databases_path,\"Reference_Genome/GRCh38p14/Ensembl/Homo_sapiens_GRCh38_dna_primary_assembly.fa\")\n",
    "# GWAS Associated bed and sequences path\n",
    "gwas_associated_bed_path = os.path.join(databases_path, \"Ensembl/Variation/110/gwas_associated_sequences/beds\")\n",
    "gwas_associated_seq_path = os.path.join(databases_path, \"Ensembl/Variation/110/gwas_associated_sequences/ref_sequences\")\n",
    "rand_bed_path = os.path.join(databases_path, \"Ensembl/Variation/110/random_sequences/beds\")\n",
    "rand_seq_path = os.path.join(databases_path, \"Ensembl/Variation/110/random_sequences/ref_sequences\")\n",
    "# Datasets path\n",
    "dataset_path = os.path.join(ensembl_path, \"chromosome_datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform csv to dataloader\n",
    "We will use the Hugging Face framework to go from a conventional Pandas dataframe to completely useful dataloaders for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import chromosome 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTCTTTTAAATGGCTACATAATTAAGTCTAAGGTGAGAATTACTGT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGTATTATTTCTATTCTTTACTTGAGAATCCAGTTTTGTAGGACTT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATTTTTTTTTTTCGAGTCAGAGTCTTGTTCTGTCACCCAGGCTGGA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTGCTTTGGGTTCTGCTGAAATCATGGATGAGTTCTTTCTTTAAAT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATTAATATTTACCCTGTATATTTTCACAGGACCATTATATTGATCA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  label\n",
       "0  TTCTTTTAAATGGCTACATAATTAAGTCTAAGGTGAGAATTACTGT...      0\n",
       "1  AGTATTATTTCTATTCTTTACTTGAGAATCCAGTTTTGTAGGACTT...      0\n",
       "2  ATTTTTTTTTTTCGAGTCAGAGTCTTGTTCTGTCACCCAGGCTGGA...      0\n",
       "3  CTGCTTTGGGTTCTGCTGAAATCATGGATGAGTTCTTTCTTTAAAT...      0\n",
       "4  ATTAATATTTACCCTGTATATTTTCACAGGACCATTATATTGATCA...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr2_dataset = pd.read_csv(os.path.join(ensembl_path, 'to_dataloaders/chr2_dataset.csv'), index_col=0)\n",
    "chr2_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['seq', 'label', '__index_level_0__'],\n",
       "        num_rows: 46102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['seq', 'label', '__index_level_0__'],\n",
       "        num_rows: 19758\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the tokenizer and the data_collator for dynamic padding. Both from the HF transformers library\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# Using the HuggingFace framework to create the Datasets and DataLoaders and split the data into train and test set\n",
    "hf_dataset = Dataset.from_pandas(chr2_dataset).train_test_split(test_size=0.3)\n",
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce2efc6377d434580abb63ab80fe393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415429bee56a4facbb7f96c99bdfc212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['seq', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 46102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['seq', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 19758\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"seq\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = hf_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'test': ['label', 'input_ids', 'token_type_ids', 'attention_mask']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"seq\", \"__index_level_0__\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "test_set = DataLoader(tokenized_datasets[\"test\"], batch_size=8, shuffle=True, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect a batch from the DataLoaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 30]),\n",
       " 'token_type_ids': torch.Size([8, 30]),\n",
       " 'attention_mask': torch.Size([8, 30]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_set:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be only the transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, 1) # Changed the second parameter from `ntoken` to 2. Because we are aiming for sequences classificication between 2 classes\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "            \"\"\"\n",
    "            src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n",
    "        output = self.transformer_encoder(src, src_mask) # Deleted parameter src_mask\n",
    "        output = output.permute(1,0,2)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moisessotelo/venvs/DNABERT_2/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "ntokens = tokenizer.vocab_size  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid =  200 # Deafult:200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 5  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 5  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding): Embedding(4096, 200)\n",
       "  (linear): Linear(in_features=200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'input_ids': tensor([[   1,    5, 2725,   40,  128,   68,  686,   34,  197,  221,   35,  326,\n",
      "           64, 2527,  174,  471,   45, 1110, 1902,  282,   60,  211,   73,  111,\n",
      "           40,  145,   27,  187,    8,    2],\n",
      "        [   1,    9,   10,   81,   32,  494,   30,  196,   20,  243,  110, 1252,\n",
      "           84,  513,   79,   38,   60, 2221,   34,  319,  195, 1057,  823,  112,\n",
      "         1470, 1198,  121,   40,    2,    3],\n",
      "        [   1,    5, 3137,   23,  164,  163,  179,  252,   82,  547, 1739,   51,\n",
      "           66, 1065,   52, 2098,  251,  103,   56,   51,  819,   36,  373,  402,\n",
      "          804,   97, 1038,    2,    3,    3],\n",
      "        [   1,  481,   78,  162, 2540,  221,   76,  242,   26,  137, 1132,  793,\n",
      "           49,  111, 1720, 3893,   32,  192,  483,   44,   54,   79,  143,  222,\n",
      "         2935,  113,   49,    2,    3,    3],\n",
      "        [   1,  191, 1202,  449,  101,   88,  292, 3405,  500,   73,   80,  239,\n",
      "           55,  549,   58,  531, 1773,  295,   65, 3678,   45,  260, 2488,   59,\n",
      "          422,    8,    2,    3,    3,    3],\n",
      "        [   1,    5,  184,  331,   55,   68, 2263,   75,   15,  248,  579, 3188,\n",
      "          382,   65,  674,  123, 1367,  116,  105,   63, 1822,  659,   39,  419,\n",
      "          597, 3206,    2,    3,    3,    3],\n",
      "        [   1, 1040,   22,  252,   37,  269,  595,  108,   29,  136,   78,   42,\n",
      "          160,   68,  565,  102,  132,  277,   38,   89,   77, 3721, 2708, 1179,\n",
      "           38,   63,   27,   19,  124,    2],\n",
      "        [   1,    5,   93, 1659,   13,  542,   27,  165,  686, 1268,  152,   34,\n",
      "          213,   51,  294,  134,  177, 2613, 2349, 1000, 2565,   92,  460,  171,\n",
      "          632,  152,   17,    8,    2,    3]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0]], device='cuda:0'), 'labels': tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for batch, elements in enumerate(train_set):\n",
    "    elements = {k: v.to(device) for k, v in elements.items()}\n",
    "    print(batch, elements)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (tensor([[   1,    5, 1782,   92, 1290,   57,  252,  532, 1346,  104,  815, 3069,\n",
      "          188,   36,  114,  374,  301,   51,   74,  190,  596, 3366,  654, 3094,\n",
      "          385,   32,    2,    3,    3,    3],\n",
      "        [   1,   83, 3802,  596,   27,  259,   46,   57, 1069,  101,   77,   76,\n",
      "         1212,   97, 1905, 3934, 1255,   48,   74, 2768,  811,  165,   34,  998,\n",
      "           34,  697,    6,    2,    3,    3],\n",
      "        [   1,    9,   84, 1784,   81,   31, 1968,   29,  187,  654,  205,  962,\n",
      "           26,  930,   96,   26,  516,  125,  746,   77,  107,   45,  153,   84,\n",
      "           89,   42,   36,  281,    6,    2],\n",
      "        [   1, 2791,  120,   28,  238,   39,  243,  426, 2672,  602,  336,   87,\n",
      "          343,  227,   36,  104,  419,  327,  495,   87, 1115,   47,  847, 2545,\n",
      "          278,    8,    2,    3,    3,    3],\n",
      "        [   1,  136,  802,  570, 1333,   74,   85, 3117, 3066,   38,   36,  415,\n",
      "          110,  559, 1502, 1215, 1797,  125,  842,  237,  125, 4031,   96,    8,\n",
      "            2,    3,    3,    3,    3,    3],\n",
      "        [   1,  115,   72,  200,  447,   33,  362,   78,   99,   36, 2144,  354,\n",
      "           52,  152,   17,  547,   36,  427,   93,  401, 1048,  546,   53,  568,\n",
      "          166, 2369,   13,  343,  467,    2],\n",
      "        [   1,    5,   73,  853, 2124, 1125,  747,  205,  116,  179,  930,   21,\n",
      "           61,   55,  802,   36,  171, 3296,  139,   28,  142,  113, 3036,  305,\n",
      "           14,    2,    3,    3,    3,    3],\n",
      "        [   1,    5, 4055,  276,   56,  244, 1024,  816, 1577, 1277,   39,   94,\n",
      "          312,  109,   41,  151,   23,  164,  197,   27,  127,  303,  325,  978,\n",
      "          233,  278,   52,    8,    2,    3]], device='cuda:0'), tensor([0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "for batch, elements in enumerate(train_set):\n",
    "    #elements = {k: v.to(device) for k, v in elements.items()}\n",
    "    X, y = elements['input_ids'].to(device), elements['labels'].to(device)\n",
    "    print(batch, (X,y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i<1:\n",
    "    for batch in test_set:\n",
    "        #elements = {k: v.to(device) for k, v in elements.items()}\n",
    "        print(batch)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(X)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loop function\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, elements in enumerate(dataloader):\n",
    "        X, y = elements['input_ids'].to(device), elements['labels'].to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Loop\n",
    "We use this one to make sure the model is learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop function\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, elements in dataloader:\n",
    "            X, y = elements['input_ids'].to(device), elements['labels'].to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_set, model, loss_fn, optimizer)\n",
    "    test(test_set, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_logits = flatten(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to implemet with HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoModel\n",
    "\n",
    "checkpoint = \"zhihan1996/DNABERT-2-117M\"\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(checkpoint, num_labels=2, trust_remote_code=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_set)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_set:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNABERT_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
